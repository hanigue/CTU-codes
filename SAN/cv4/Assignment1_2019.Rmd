---
title: "Assignment 1: Regression"
output:
  html_document:
    df_print: paged
---

This is the first assignment of B4M36SAN in 2019.
Write your solution directly into this document and submit it to BRUTE.
The deadline is 28.9.2019.

First of all go through the code and fill the missing part (0.5 points).

```{r prepare, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
library("MASS") # Includes the Boston dataset
library("formula.tools") # Contains a helper function
library("gam") # Generalized additive models
library("MLmetrics") # Generalized additive models

set.seed(7) # Set a fixed random seed for measurement replicability
    

testMeanSquareError = function(modelType, modelStruct, dataset) {
  datasetSize <- nrow(dataset)
  sampleSize <- floor(0.8 * datasetSize)
  trainIndices <- sample(seq_len(datasetSize), size = sampleSize)
  trainSet <- dataset[trainIndices, ]
  testSet <- dataset[-trainIndices, ]
  fit <- modelType(modelStruct, data = trainSet)
  independentVariable <- formula.tools::lhs(modelStruct)
  
  predictions <- predict(fit, testSet)
  groundTruth <- getElement(testSet, independentVariable)
  mse <- MSE(y_pred=predictions, y_true=groundTruth)# write the code to compute Mean Square Error
  mse
}
```

We will attempt to predict the `medv` variable in the Boston dataset using the `lstat` and `rm` variables.
That is, predict median value of owner-occupied homes in $1000s using ower status of the population (percent)
and average number of rooms per dwelling.

Lets inspect the dataset

```{r}
help(Boston)
summary(Boston)
attach(Boston)
plot(medv, lstat) # remember a few relationships/plots from the lecture
plot(medv, rm) # remember a few relationships/plots from the lecture
plot(lstat, rm)
```

Example usage of the function, to estimate the error of a linear model:


```{r}
testMeanSquareError(lm, medv ~ lstat + rm, Boston)
```

Construct and measure the performance of the following models (include your code in this document, 2 points):

1. The linear model above

```{r}
fit=lm(medv ~ lstat + rm,data=Boston)
summary(fit)
coef(summary(fit))
testMeanSquareError(lm, medv ~ lstat + rm, Boston)
plot(fit)
```

From the results we see that both p-values and resulting p-value are really small (denoted by ***) so they are significant.
That can be also confirmed by the t-values. This means, that we reject the Null Hypothesis that the coeficients are 0, e.g. do
not contribute to the prediction of resulting value.

## t-value

We can interpret the t-value something like this. A larger t-value indicates that it is less likely that the coefficient is not equal to zero purely by chance. So, higher the t-value, the better.

Pr(>|t|) or p-value is the probability that you get a t-value as high or higher than the observed value when the Null Hypothesis (the Î² coefficient is equal to zero or that there is no relationship) is true. So if the Pr(>|t|) is low, the coefficients are significant (significantly different from zero). If the Pr(>|t|) is high, the coefficients are not significant.

2. A model polynomial in one variable and linear in the other (Determine a suitable polynomial degree >= 2)

```{r}
fit=lm(medv ~ poly(lstat,7) + rm,data=Boston)
coef(summary(fit))
testMeanSquareError(lm, medv ~ poly(lstat,7) + rm, Boston)
fit.l2=lm(medv ~ poly(lstat,2) + rm,data=Boston)
fit.l3=lm(medv ~ poly(lstat,3) + rm,data=Boston)
fit.l4=lm(medv ~ poly(lstat,4) + rm,data=Boston)
fit.l5=lm(medv ~ poly(lstat,5) + rm,data=Boston)
fit.l6=lm(medv ~ poly(lstat,6) + rm,data=Boston)
fit.l7=lm(medv ~ poly(lstat,7) + rm,data=Boston)
fit.l8=lm(medv ~ poly(lstat,8) + rm,data=Boston)
fit.l9=lm(medv ~ poly(lstat,9) + rm,data=Boston)
anova(fit.l2,fit.l3,fit.l4,fit.l5,fit.l6,fit.l7,fit.l8,fit.l9)
coef(summary(fit.7))
```

3. A model polynomial in both variables (Determine a suitable polynomial degrees >= 2)

```{r}
fit.2.2=lm(medv ~ poly(lstat,2) + poly(rm,2),data=Boston)
fit.2.3=lm(medv ~ poly(lstat,2) + poly(rm,3),data=Boston)
fit.3.2=lm(medv ~ poly(lstat,3) + poly(rm,2),data=Boston)
fit.3.3=lm(medv ~ poly(lstat,3) + poly(rm,3),data=Boston)
fit.4.4=lm(medv ~ poly(lstat,4) + poly(rm,4),data=Boston)
anova(fit.2.2,fit.2.3,fit.3.2,fit.3.3,fit.4.4)
testMeanSquareError(lm, medv ~ poly(lstat,2) + poly(rm,2), Boston)
```

4. A model polynomial in both variables that clearly overfits, but still try to keep the degrees as low as possible.

```{r}
gam1=lm(medv~ns(lstat,4)+rm,data=Boston) # simple linear model when using bs() and ns()
testMeanSquareError(lm, medv ~ ns(lstat,4)+rm, Boston)

```

5. A generalized additive model (gam) using natural spline for one variable and linear function for the other (Use the same degree as in 2.)

```{r}
gam1=lm(medv~ns(lstat,4)+rm,data=Boston) # simple linear model when using bs() and ns()
testMeanSquareError(lm, medv ~ ns(lstat,4)+rm, Boston)
```

6. A generalized additive model (gam) using natural spline for both variables. (Use the same degrees as in 3)

```{r}
testMeanSquareError(lm, medv ~ ns(lstat,4)+ns(rm,4), Boston)
```

7. A linear combination of natural splines in either variables (Determine a suitable degrees >= 2)

```{r}
gam.m3=gam(medv~s(lstat,4) + s(rm,5),data=Boston) # gam must be used to compile smoothing splines and/or local regression
par(mfrow=c(1,3))
plot(gam.m3, se=TRUE,col="blue")
```

8. Some other kind of model that you choose.

```{r}
```

Answer the following questions (write the answers into this document, 2.5 points):

1. Which model had the best measured performance?
2. Is the best model relatively simple or complicated among the other models? 
3. Did the GAM models perform better than the polynomial ones? Explain why you think it was or was not the case. 
4. For the models that did not perform well, give an explanation why it was the case.
5. Discuss briefly: What would change if we used cross-valiadation instead of a simple train/test measurement?
6. Is the difference between the best and the other models large? Is the difference statistically significant? Propose a method that works with an interval error estimate.
